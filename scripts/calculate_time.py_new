#!/usr/bin/python

import os
import sys
import subprocess
import re
import fnmatch
import statistics
from optparse import OptionParser
from time import gmtime, strftime

def error(msg):
	print('{0:s} tmp={1:s}'.format(msg, tmp))
	sys.exit(1);

parser=OptionParser()
parser.add_option("--svcomp", dest="svcomp")
parser.add_option("--predictions-file", dest="prediction_file")
parser.add_option("--answers-file", dest="answers_file")
parser.add_option("--times-file", dest="times_file")
parser.add_option("--tables-dir", dest="tables_dir")
#parser.add_option("--cats-file", dest="cats_file")
parser.add_option("--max-ex", dest="max_ex", default='10')
parser.add_option("--min-ex", dest="min_ex", default='1')
parser.add_option("--excluded-tools", dest="excluded_tools")
parser.add_option("--log", dest="log")
parser.add_option("--memsafety", dest="memsafety", action="store_true")
parser.add_option("--wo-memsafety", dest="wo_memsafety",action="store_true")
parser.add_option("--hv",dest="hv")
parser.add_option("--debug",dest="debug",action="store_true")
parser.add_option("--files-all",dest="files_all")
(options, args) = parser.parse_args()

if (options.svcomp != None): options.svcomp="svcomp"+options.svcomp

if ( options.svcomp != "svcomp14" and options.svcomp != "svcomp15" ):
	error("unknown version of svcomp")
elif ( options.prediction_file == None ):
	error("predictions file is empty")
#elif ( options.answers_file == None ):
#	error("answers file is empty")
#elif ( options.times_file == None ):
#	error("times file is empty")
#elif ( options.cats_file == None ):
#	error("cats file is empty")
elif ( options.max_ex == None ):
	error("specify max_ex")
elif ( options.tables_dir == None ):
	error("specify --tables-dir")
elif ( options.files_all == None ):
	error("specify --files_all")

if ( options.answers_file == None ):
	options.answers_file = 'data/' + options.svcomp + '/competition_results/working_materials/answers'
if ( options.times_file == None ):
	options.times_file = 'data/' + options.svcomp + '/competition_results/working_materials/times'
if (options.log == None):
	options.log = options.tables_dir + '/log_calculate_time'
print('log={0}\n'.format(options.log))

BENCHMARK_DIR=os.environ['BENCHMARK_DIR'] #"/home/demy/phd/repos/proseed/variable_roles/benchmarks"
BENCHMARK = BENCHMARK_DIR #+ '/' + options.svcomp #"/svcomp14"
PLOTS_DIR=os.environ['SVM_PROCESSED_RESULTS_DIR'] #BENCHMARK_DIR + "/../var_roles/pani-paper-benchmarks/trunk/fase_pldi_2015/plots"
tmp=subprocess.check_output("mktemp", shell=True).strip()

#print('BENCHMARK={0}'.format(BENCHMARK))

file_nums=[]
excluded_tools=[]
if ( options.excluded_tools != None ):
	excluded_tools=[options.excluded_tools.split()]
	suff="wo_" + re.sub(' ', '_', options.excluded_tools)
	table_tool_places_file= table_tool_places_file + suff
	table_used_tools_file= table_used_tools_file + suff
	table_succ_fail_file= table_succ_fail_file + suff


table_tool_places_file=options.tables_dir + "/places_table.txt"
table_used_tools_file=options.tables_dir + "/used_tools_table.txt"
table_succ_fail_file= options.tables_dir + "/succ_fail_table.txt"

ftable_tool_places=open(table_tool_places_file, 'w')
ftable_used_tools=open(table_used_tools_file, 'w')
ftable_succ_fail=open(table_succ_fail_file, 'w')

flog=open(options.log, 'w')
flog.write('tmp={0:s}\n'.format(tmp))
flog.write('{0:s}\n'.format(subprocess.check_output("date +'%D %X'", shell=True)))

cat_tool_scores={}
cat_tool_runtimes={}
cat_tool_places={}
cat_tool_places_wo_ps={}
tool_medals={}
ps_places_per_file={}
choice={}
file_num={}
tool_succ_fail={}
SubCat={}
cat_best_tool={}
cat_tool_nonparticip_chosen={}
non_particip={}

def enum(**enums):
	return type('Enum', (), enums)

def print_file(filename):
	with open (filename, 'r') as fin:
		flog.write('{0}\n'.format(fin.read()))

SuccFailType=enum(succ=1, fail=2, unknown=3)
all_succ_fail = [SuccFailType.succ, SuccFailType.fail, SuccFailType.unknown]

if ( options.svcomp == "svcomp14" ):
	CatsType=enum(
			BitVectors=1,
			Concurrency=2,
			ControlFlowInteger=3,
			Loops=4,
			ProductLines=5,
			DeviceDrivers64=6,
			HeapManipulation=7,
			MemorySafety=8,
			Recursive=9,
			Sequentialized=10,
			Simple=11,
			Overall=12,
			ControlFlow=13
		)

	cat_dict = {
				CatsType.BitVectors : 'BitVectors',
				CatsType.Concurrency : 'Concurrency',
				CatsType.ControlFlowInteger : 'ControlFlowInteger',
				CatsType.Loops : 'Loops',
				CatsType.ProductLines : 'ProductLines',
				CatsType.DeviceDrivers64 : 'DeviceDrivers64',
				CatsType.HeapManipulation : 'HeapManipulation',
				CatsType.MemorySafety : 'MemorySafety',
				CatsType.Recursive : 'Recursive',
				CatsType.Sequentialized : 'Sequentialized',
				CatsType.Simple : 'Simple',
				CatsType.Overall: 'Overall',
				CatsType.ControlFlow: 'ControlFlow'
				}

	simple_cats=[
					CatsType.BitVectors,
					CatsType.Concurrency,
					CatsType.ControlFlowInteger,
					CatsType.Loops,
					CatsType.ProductLines,
					CatsType.DeviceDrivers64,
					CatsType.HeapManipulation,
					CatsType.MemorySafety,
					CatsType.Recursive,
					CatsType.Sequentialized,
					CatsType.Simple
		]

	compound_cats = [CatsType.Overall, CatsType.ControlFlow]

	SubCat[CatsType.ControlFlow]=[CatsType.ControlFlowInteger, CatsType.Loops, CatsType.ProductLines]
	SubCat[CatsType.Overall]=simple_cats

	cats_none=12 #len(simple_cats)+1

	cat_best_tool[CatsType.BitVectors]=9 #llbmc
	cat_best_tool[CatsType.Concurrency]=5 #cseq-lazy
	cat_best_tool[CatsType.ControlFlowInteger]=13 #ufo
	cat_best_tool[CatsType.Loops]=2 # 9 #llbmc 2 #cbmc
	cat_best_tool[CatsType.ProductLines]=10 #predator
	cat_best_tool[CatsType.DeviceDrivers64]=1 #blast
	cat_best_tool[CatsType.HeapManipulation]=2 # 10" # predator 2 #cbmc
	cat_best_tool[CatsType.MemorySafety]=3 # 9" #llbmc #3 #cpachecker
	cat_best_tool[CatsType.Recursive]=2 # 13" #ultimateAutomizer  #2 #cbmc
	cat_best_tool[CatsType.Sequentialized]=7 #esbmc
	cat_best_tool[CatsType.Simple]=2 # 12" #ufo #2 #cbmc
	cat_best_tool[cats_none]=2 #9 #llbmc #2 #cbmc

	non_particip[CatsType.BitVectors] = [1, 4, 5, 6, 8, 12, 13, 14]
	non_particip[CatsType.Concurrency] = [1, 3, 4, 8, 9, 10, 13, 14, 15]
	non_particip[CatsType.ControlFlowInteger] = [5, 6, 12]
	non_particip[CatsType.Loops] = [5, 6, 12]
	non_particip[CatsType.ProductLines] = [5, 6, 12, 14, 15]
	non_particip[CatsType.DeviceDrivers64] = [4, 5, 6, 9, 12, 14, 15]
	non_particip[CatsType.HeapManipulation] = [1, 5, 6, 8, 12, 13, 14]
	non_particip[CatsType.MemorySafety] = [1, 5, 6, 8, 12, 13, 14, 15]
	non_particip[CatsType.Recursive] = [1, 3, 4, 5, 6, 8, 12, 13]
	non_particip[CatsType.Sequentialized] = [1, 3, 4, 5, 6, 8, 12]
	non_particip[CatsType.Simple] = [4, 5, 6, 9, 10, 12, 14, 15]

	tools_num=15
	MetaToolsType = enum(tools_none = tools_num+1, tmax=tools_num+2, ps=tools_num+3,
						perfect_ps=tools_num+4, perfect_ps2=tools_num+5)#,
#						perfect_ps22=tools_num+6)

	toolname_dict = {
						1 : 'blast',
						2 : 'cbmc',
						3 : 'cpachecker',
						4 : 'cpalien',
						5 : 'cseq-lazy',
						6 : 'cseq-mu',
						7 : 'esbmc',
						8 : 'fbit',
						9 : 'llbmc',
						10 : 'predator',
						11 : 'symbiotic',
						12 : 'threader',
						13 : 'ufo',
						14 : 'ultimateAutomizer',
						15 : 'ultimateKojak',
						MetaToolsType.tools_none : 'none',
						MetaToolsType.tmax: 'max',
						MetaToolsType.ps: 'ps',
						MetaToolsType.perfect_ps: 'perfect_ps',
						MetaToolsType.perfect_ps2: 'perfect_ps2'#,
#						MetaToolsType.perfect_ps22: 'perfect_ps22'
					}

	incorrect_false_score=-4
	incorrect_true_score=-8

elif ( options.svcomp == "svcomp15" ):
	CatsType=enum(
			Arrays=1,
			BitVectors=2,
			Concurrency=3,
			ControlFlowInteger=4,
			ECA=5,
			Loops=6,
			ProductLines=7,
			DeviceDrivers64=8,
			Floats=9,
			HeapManipulation=10,
			MemorySafety=11,
			Recursive=12,
			Sequentialized=13,
			Simple=14,
			Termination=15,
			Overall=16,
			ControlFlow=17
		)

	cat_dict = {
				CatsType.Arrays : 'Arrays',
				CatsType.BitVectors : 'BitVectors',
				CatsType.Concurrency : 'Concurrency',
				CatsType.ControlFlowInteger : 'ControlFlowInteger',
				CatsType.ECA : 'ECA',
				CatsType.Loops : 'Loops',
				CatsType.ProductLines : 'ProductLines',
				CatsType.DeviceDrivers64 : 'DeviceDrivers64',
				CatsType.Floats : 'Floats',
				CatsType.HeapManipulation : 'HeapManipulation',
				CatsType.MemorySafety : 'MemorySafety',
				CatsType.Recursive : 'Recursive',
				CatsType.Sequentialized : 'Sequentialized',
				CatsType.Simple : 'Simple',
				CatsType.Termination : 'Termination-crafted',
				CatsType.Overall: 'Overall',
				CatsType.ControlFlow: 'ControlFlow'
				}

	simple_cats=[
					CatsType.Arrays,
					CatsType.BitVectors,
					CatsType.Concurrency,
					CatsType.ControlFlowInteger,
					CatsType.ECA,
					CatsType.Loops,
					CatsType.ProductLines,
					CatsType.DeviceDrivers64,
					CatsType.Floats,
					CatsType.HeapManipulation,
					CatsType.MemorySafety,
					CatsType.Recursive,
					CatsType.Sequentialized,
					CatsType.Simple,
					CatsType.Termination
		]

	compound_cats = [CatsType.Overall, CatsType.ControlFlow]
	cats_none=16 #len(simple_cats)+1

	SubCat[CatsType.ControlFlow]=[CatsType.ControlFlowInteger, CatsType.Loops, CatsType.ProductLines, CatsType.ECA]
	SubCat[CatsType.Overall]=simple_cats

	cat_best_tool[CatsType.Arrays]=19 #smack
	cat_best_tool[CatsType.BitVectors]=8 #esbmc
	cat_best_tool[CatsType.Concurrency]=13 #cseq-lazy
	cat_best_tool[CatsType.ControlFlowInteger]=8 #esbmc
	cat_best_tool[CatsType.ECA]=6 #cpachecker
	cat_best_tool[CatsType.Loops]=9 # forest
	cat_best_tool[CatsType.ProductLines]=8 #esbmc
	cat_best_tool[CatsType.DeviceDrivers64]=3 #blast
	cat_best_tool[CatsType.Floats]=5 #cbmc
	cat_best_tool[CatsType.HeapManipulation]=17 # predator
	cat_best_tool[CatsType.MemorySafety]=6 # cpachecker
	cat_best_tool[CatsType.Recursive]=19 # smack
	cat_best_tool[CatsType.Sequentialized]=8 #esbmc
	cat_best_tool[CatsType.Simple]=18 # seahorn
	cat_best_tool[CatsType.Termination]=1 #aprove
	cat_best_tool[cats_none]=6 #cpachecker

	non_particip[CatsType.Arrays]=[1, 2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22]
	non_particip[CatsType.BitVectors]=[1, 3, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22]
	non_particip[CatsType.Concurrency]=[1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 16, 17, 19, 20, 21]
	non_particip[CatsType.ControlFlowInteger]=[1, 2, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22]
	non_particip[CatsType.ECA]=[1, 2, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22]
	non_particip[CatsType.Loops]=[1, 2, 7, 10, 11, 12, 13, 14, 15, 17, 22]
	non_particip[CatsType.ProductLines]=[1, 2, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22]
	non_particip[CatsType.DeviceDrivers64]=[1, 2, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22]
	non_particip[CatsType.Floats]=[1, 2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22]
	non_particip[CatsType.HeapManipulation]=[1, 2, 3, 7, 9, 11, 12, 13, 14, 15, 16, 22]
	non_particip[CatsType.MemorySafety]=[1, 2, 3, 7, 8, 9, 11, 12, 13, 15, 16, 18, 19, 22]
	non_particip[CatsType.Recursive]=[1, 3, 4, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22]
	non_particip[CatsType.Sequentialized]=[1, 2, 3, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22]
	non_particip[CatsType.Simple]=[1, 2, 4, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 22]
	non_particip[CatsType.Termination]=[2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 21, 22]

	tools_num=22
	MetaToolsType = enum(tools_none = tools_num+1, tmax=tools_num+2, ps=tools_num+3,
						perfect_ps=tools_num+4, perfect_ps2=tools_num+5)#,
#						perfect_ps22=tools_num+6)

	toolname_dict = {
						1 : 'aprove',
						2 : 'beagle',
						3 : 'blast',
						4 : 'cascade',
						5 : 'cbmc',
						6 : 'cpachecker',
						7 : 'cparec',
						8 : 'esbmc',
						9 : 'forest',
						10 : 'forester',
						11 : 'function',
						12 : 'hiptnt',
						13 : 'lazycseq',
						14 : 'map2check',
						15 : 'mucseq',
						16 : 'perentie',
						17 : 'predatorhp',
						18 : 'seahorn',
						19 : 'smack',
						20 : 'ultimateautomizer',
						21 : 'ultimatekojak',
						22 : 'ulcseq',
						MetaToolsType.tools_none : 'none',
						MetaToolsType.tmax: 'max',
						MetaToolsType.ps: 'ps',
						MetaToolsType.perfect_ps: 'perfect_ps',
						MetaToolsType.perfect_ps2: 'perfect_ps2'#,
#						MetaToolsType.perfect_ps22: 'perfect_ps22'
					}

	incorrect_false_score=-6
	incorrect_true_score=-12


if ( options.memsafety == True ):
	simple_cats=[CatsType.MemorySafety]
	compound_cats=[]
elif (options.wo_memsafety == True):
	simple_cats.remove(CatsType.MemorySafety)

cats = simple_cats + compound_cats
cat_paths={}

MetaToolsType = enum(tools_none = tools_num+1, tmax=tools_num+2, ps=tools_num+3,
						perfect_ps=tools_num+4, perfect_ps2=tools_num+5)#,
#						perfect_ps22=tools_num+6)
svcomp_tools = range(1, tools_num+1)
print('svcomp_tools={0}'.format(svcomp_tools))
meta_tools = [MetaToolsType.tmax, MetaToolsType.ps,
				MetaToolsType.perfect_ps2, #MetaToolsType.perfect_ps22,
				MetaToolsType.perfect_ps]
tools = svcomp_tools + meta_tools
print('tools={0}'.format(tools))

def is_excluded_tool(tool):
	return tool in excluded_tools

def is_meta_tool(tool):
	return tool in meta_tools

def get_exp_res(filename):
	true_pos = filename.find('_true')
	false_pos = filename.find('_false')

	if ( false_pos < 0 ) or ( true_pos >= 0 and true_pos < false_pos ):
		expected_res=True
	elif ( false_pos > 0 ):
		expected_res=False
	else:
		error('unknown expected result for file ' + filename)

	return expected_res


def get_max_score(filename):
	expected_res = get_exp_res(filename)

	if ( expected_res == True ):
		max_possible_score=2
	else:
		max_possible_score=1

	return max_possible_score

def get_num_score(filename, answer):
	if ( answer == 'unknown' or answer == '?' ): num_score=0
	else:
		expected_res = get_exp_res(filename)
		if ( expected_res == True) :
			if ( answer == 'true' ): num_score=2
			elif ( answer == 'false' ): num_score=incorrect_false_score
			else: error("incorrect answer: {0}".format(answer))
		else:
			if ( answer == 'false' ): num_score=1
			elif ( answer == 'true' ): num_score=incorrect_true_score
			else: error("incorrect answer: {0}".format(answer))

	#max_possible_score = get_max_score(filename)

	if ( num_score > 0 ): succ_fail=SuccFailType.succ
	elif ( num_score == 0 ): succ_fail=SuccFailType.unknown
	else: succ_fail=SuccFailType.fail

	return (num_score, succ_fail)

def get_tool_name(tool):
	return toolname_dict[tool]

def get_cat_name(cat):
	return cat_dict[cat]

def get_cat_id(cat_str):
	for cat_id, cat_name in cat_dict.iteritems():
		if cat_str == cat_name: return cat_id

	error('cat {0} not found in dictionary'.format(cat))

def succ_fail_to_str(succ_fail):
	d = {
		SuccFailType.succ : 'succ',
		SuccFailType.fail : 'fail',
		SuccFailType.unknown: 'unknown'
	}
	return d[succ_fail]

def tool_opt_out(tool, cat):
	return tool in non_particip[cat]

def arr_to_str(arr):
	return ''.join(x for x in arr)

def compute_perc(x, y):
	if y == 0: res=float('nan')
	else: res=100 * float(x) / y
	return res

def init():
	if ( exnum == min_ex ):
		for catid in simple_cats:
			cat=get_cat_name(catid)
			config=BENCHMARK + '/' + cat + '.set'
#		for config in subprocess.check_output('find {0:s} -name "*.set" | grep -v Stateful | grep -v DriverChallenges'.format(BENCHMARK), shell=True).split():
#			cat=subprocess.check_output('basename ' + config, shell=True)
#			cat=cat[0:str.find(cat,'.')]
			tmp_cat = '{0}_{1}'.format(tmp, cat)
			#sys.exit(0)

			config_file=open(config,'r')
			cat_id = get_cat_id(cat)
			cat_paths[cat_id]=[]
			for line in config_file:
				line = line.strip()
				if line == "": continue
				cat_paths[cat_id].append(line);
				line = '{0}/{1}'.format(BENCHMARK, line)
				#print('line=', line)
				os.system('find {0} -path "{1}" >> {2}'.format(BENCHMARK, line, tmp_cat))
			os.system("cat {0} | sed 's!^{1}/!!' | sort > {2} && mv {2} {3}".format(tmp_cat, BENCHMARK, tmp, tmp_cat))

			config_file.close()

	cmd="LC_ALL=C sort {0} > {1} && tail -n +2 {1} | cat -n - | sed 's!^[ ]*!!;s!\\t! !' > {1}_files && cut -f 1 -d ' ' {1}_files  > {1}_1 && cut -f 2 -d ' ' {1}_files > {1}_2 && paste {1}_2 {1}_1 > {1}_files &&  cut -f 1 -d ' ' {2}_{3} | tail -n +2 > {1}_ans_files && LC_ALL=C join {1}_files {1}_ans_files | cut -f 2 -d ' ' | tr '\\n' ' '".format(options.files_all,tmp,options.prediction_file,exnum)
	output=subprocess.check_output(cmd, shell=True)
	file_nums=output.split()
	print('len(file_nums)={0} cmd={1}'.format(len(file_nums), cmd))

	for cat in cats:

		file_num[(cat, ex)]=0
		for tool in tools:
			cat_tool_scores[(cat, tool, ex)]=0
			#print('cat_tool_scores[({0}, {1}, {2})]=0'.format(cat, tool , ex))
			cat_tool_runtimes[(cat, tool, ex)]=0
			participant = not is_meta_tool(tool)
			#print('tool={0} participant={1}\n'.format(tool, participant))

			if ( participant ):
				ps_places_per_file[(cat, tool, ex)]=0
				choice[(cat, tool, ex)]=0
				cat_tool_nonparticip_chosen[(cat, tool, ex)]=0

			if ( tool != MetaToolsType.tmax ):
				for succ_fail in all_succ_fail:
					tool_succ_fail[(cat, tool, succ_fail, ex)]=0

			if ( participant or tool == MetaToolsType.ps ):
				for place in range(1, MetaToolsType.tools_none+1): tool_medals[(tool, place, ex)]=0

			if ( exnum == min_ex ):
				file_num[(cat,EXSUM)]=0
				cat_tool_scores[(cat, tool, EXSUM)]=0
				cat_tool_runtimes[(cat, tool, EXSUM)]=0

				if ( participant ):
					#print('ps_places_per_file[({0}, {1}, {2})]=0\n'.format(cat, tool, EXSUM))
					ps_places_per_file[(cat, tool, EXSUM)]=0
					choice[(cat, tool, EXSUM)]=0
					cat_tool_nonparticip_chosen[(cat, tool, EXSUM)]=0


				if ( tool != MetaToolsType.tmax ):
					for succ_fail in all_succ_fail:
						tool_succ_fail[(cat, tool, succ_fail, EXSUM)]=0

				if ( participant or tool == MetaToolsType.ps ):
					for place in range(1, MetaToolsType.tools_none+1): tool_medals[(tool, place, EXSUM)]=0

		choice[(cat, MetaToolsType.tools_none, ex)]=0
		ps_places_per_file[(cat, MetaToolsType.tools_none, ex)]=0

		if ( exnum == min_ex ):
			choice[(cat, MetaToolsType.tools_none, EXSUM)]=0
			ps_places_per_file[(cat, MetaToolsType.tools_none, EXSUM)]=0

	if ( exnum == min_ex ):
		ftable_tool_places.write('Category')
		ftable_succ_fail.write('Category')
		ftable_used_tools.write('Category')
		for tool in tools :
			if not ( is_excluded_tool(tool) or tool == MetaToolsType.tmax ):
				tool_str='\t{0}'.format(get_tool_name(tool))
				ftable_tool_places.write(tool_str)
				ftable_succ_fail.write(tool_str)

				if not ( is_meta_tool(tool) ):
					ftable_used_tools.write(tool_str)

		ftable_tool_places.write('\n')
		ftable_succ_fail.write('\n')
		ftable_used_tools.write('\tNone\n')

def get_file_category(filename):
	cat=-1
	#filename=re.sub('\.', '\\\\\\\\.', filename)
	#print('filename={0}\n'.format(filename))

	for c in simple_cats:
		for p in cat_paths[c]:
			if fnmatch.fnmatch(filename, p): return c
	
#		cmd = 'grep "{0}" {1}_{2}'.format(filename, tmp, get_cat_name(c))
#		#print('cmd={0}\n'.format(cmd))
#		try:
#			subprocess.check_output(cmd, shell=True)
#			cat = c
#			break
#		except subprocess.CalledProcessError: 	
#			continue

	if ( cat == -1 ): error("couldn't detect category for {0}".format(filename))
	return cat

def get_predicted_file_category(filename):
	filename=re.sub('\.', '\\\\.', filename)
	cmd = 'grep "{0}" {1}_{2}| cut -f 2 -d \' \''.format(filename, options.cats_file, exnum)
	#print('cmd={0}\n'.format(cmd))
	cat_str=subprocess.check_output(cmd, shell=True)
	if ( cat_str == '' ): error('cannot find predicted file category filename={0} cat_str={1} cats_file={2}_{3}\n'.format(filename, cat_str, options.cats_file, exnum))
	return int(cat_str) + 1

def tool_distribution():
	flog.write('\nTool distribution:\n')

	with open(tmp, 'w') as ftmp:
		for tool in range(1, MetaToolsType.tools_none+1):
			perc = compute_perc(choice[(Overall, tool, ex)], file_num[(Overall,ex)])
			ftmp.write('{0:s} {1:d} ({2:.1f})\n'.format(get_tool_name(tool), choice[(Overall, tool, ex)], perc))

	os.system('cat {0} | sort -k 2n > {0}1 && mv {0}1 {0}', tmp)
	print_file(tmp)

def get_tool_ans(tool, filename):
	col=tool+1
	filename_re=re.escape(filename)
	cmd='grep "{0}" {1} | cut -d \' \' -f {2}'.format(filename_re, options.answers_file, col)
	answer=subprocess.check_output(cmd, shell=True).strip()
	return answer

def get_tool_runtime(tool, filename):
	col=tool+1
	filename_re=re.escape(filename)
	cmd = 'grep "{0}" {1} | cut -d \' \' -f {2} | sed \'s%?%0%g\''.format(filename_re, options.times_file, col)
	runtime=float(subprocess.check_output(cmd, shell=True).strip())
	return runtime;


def get_hvtool_score_runtime(filename):
	cbmc=5; cpachecker=6; none=23;
	cpachecker_ans = get_tool_ans(cpachecker, filename);
	cpachecker_rt = get_tool_runtime(cpachecker, filename);

	if ( cpachecker_ans == 'unknown' or cpachecker == '?' ):
		cbmc_ans = get_tool_ans(cbmc, filename)
		cbmc_rt = get_tool_runtime(cbmc, filename)
		if ( options.hv == '1' or cbmc_ans == 'false'):
			tool=cbmc; ans=cbmc_ans; rt=cbmc_rt;
		else:
			tool=none; ans='unknown'; rt=0
	else:
		tool=cpachecker; ans=cpachecker_ans; rt=cpachecker_rt
	
	(num_score, succ_fail) = get_num_score(filename, ans)
	return (num_score, succ_fail, rt, ans, tool)

def get_score_runtime_tool(tool,num,filename):
	if len(tool_res[num]) == 0:
		filename_re=re.escape(filename)

		for tool in svcomp_tools:
			col=tool+1
			cmd='grep "{0}" {1} | cut -d \' \' -f {2}'.format(filename_re, options.answers_file, col)
			#print('cmd={0}\n'.format(cmd))
			answer=subprocess.check_output(cmd, shell=True).strip()
			cmd = 'grep "{0}" {1} | cut -d \' \' -f {2} | sed \'s%?%0%g\''.format(filename_re, options.times_file, col)
			runtime=float(subprocess.check_output(cmd, shell=True).strip())
			(num_score, succ_fail) = get_num_score(filename, answer)
			tools_res[num].append((num_score, runtime))

	(num_score, runtime)=tool_res[num][tool-1]

	if num_score > 0:
		succ_fail=SuccFailType.success
	elif num_score == 0:
		succ_fail=SuccFail.unknown
	else:
		succ_fail=SuccFail.fail

	return (num_score,succ_fail,runtime)

def get_score_runtime(tool, num, filename):
	answer=''
	if ( tool == MetaToolsType.tools_none ):
		num_score=0
		succ_fail=SuccFailType.unknown
		runtime=0
#		answer=succ_fail_to_str(SuccFailType.unknown)
	else:
		(num_score, succ_fail,runtime) = get_num_score_tool(tool, num, filename)

	return (num_score, succ_fail, runtime, answer)

def compare_results(score1, runtime1, score2, runtime2):
	return ( score1 > score2 ) or (score1 == score2 and runtime1 < runtime2)

def add_tool_result(tool, cat, score, runtime, succ_fail):
	cat_tool_scores[(cat, tool, ex)] += score
	cat_tool_runtimes[(cat, tool, ex)] += runtime
	tool_succ_fail[(cat, tool, succ_fail, ex)] += 1

def add_subcat_result(cat, subcat):
	for tool in tools:
		cat_tool_scores[(cat, tool, ex)] += float(cat_tool_scores[(subcat, tool, ex)]) / file_num[(subcat, ex)]
		cat_tool_runtimes[(cat, tool, ex)] += cat_tool_runtimes[(subcat, tool, ex)]

		if not ( is_meta_tool(tool) ):
			choice[(cat, tool, ex)] += choice[(subcat, tool, ex)]
			cat_tool_nonparticip_chosen[(cat, tool, ex)] += cat_tool_nonparticip_chosen[(subcat, tool, ex)]

		if ( tool != MetaToolsType.tmax ):
			for succ_fail in all_succ_fail:
				tool_succ_fail[(cat, tool, succ_fail, ex)] += tool_succ_fail[(subcat, tool, succ_fail, ex)]
	choice[(cat, MetaToolsType.tools_none,ex)] += choice[(subcat,MetaToolsType.tools_none,ex)]

	for place in range(1, MetaToolsType.tools_none+1):
		ps_places_per_file[(cat, place, ex)] += ps_places_per_file[(subcat, place, ex)]

	file_num[(cat,ex)] += file_num[(subcat,ex)]


def calculate_scores_runtimes():
	flog.write('\nCalculating scores and runtimes\n')

	fprediction = open('{0}_{1}'.format(options.prediction_file, exnum))
	i=0
	for line in fprediction:
		words = line.strip().split()
		#print('words', words)
		filename = words[0]; ps_tool = int(words[1])+1
		print(filename)
		cat = get_file_category(filename)
		found = False

		choice[(cat, ps_tool, ex)] += 1
		file_num[(cat,ex)] += 1
		num=file_nums[i]

		if (options.hv != None):
			(ps_num_score, ps_succ_fail, ps_runtime, ps_answer, ps_tool) = get_hvtool_score_runtime(filename);
		else:
			(ps_num_score, ps_succ_fail, ps_runtime, ps_answer) = get_score_runtime(ps_tool, num)

		add_tool_result(MetaToolsType.ps, cat, ps_num_score, ps_runtime, ps_succ_fail)
		if ( tool_opt_out(ps_tool, cat) ):
			flog.write("non-participating tool {0} chosen in cat. {1} (exp. {2})\n".format(get_tool_name(ps_tool), get_cat_name(cat), ex))
			cat_tool_nonparticip_chosen[(cat, ps_tool, ex)] += 1

		perfect_ps2_tool = cat_best_tool[cat]
		(num_score, succ_fail, runtime, answer) = get_score_runtime(perfect_ps2_tool, num)
		add_tool_result(MetaToolsType.perfect_ps2, cat, num_score, runtime, succ_fail)

#		if ( cat == CatsType.MemorySafety ):
#			predicted_cat = CatsType.MemorySafety
#		else:
#			predicted_cat = get_predicted_file_category(filename)

#		perfect_ps22_tool = cat_best_tool[predicted_cat]
#		(num_score, succ_fail, runtime, answer) = get_score_runtime(perfect_ps22_tool, filename)
#		add_tool_result(MetaToolsType.perfect_ps22, cat, num_score, runtime, succ_fail)

		ps_place=1
		perfect_ps_runtime = ps_runtime; perfect_ps_score = ps_num_score; perfect_ps_succ_fail = ps_succ_fail
		for tool in svcomp_tools:
			(num_score, succ_fail, runtime, answer) = get_score_runtime(tool, num)
			add_tool_result(tool, cat, num_score, runtime, succ_fail)
			if options.debug:
				flog.write('tool={1}, ans={2}, score={3}, rt={4}, {5}_score={6}\n'.format(filename, get_tool_name(tool), answer, num_score, runtime, get_cat_name(cat), cat_tool_scores[(cat, tool, ex)]))

			if not ( is_excluded_tool(tool) ):
				if ( ps_tool != tool ):
					if ( compare_results(num_score, runtime, ps_num_score, ps_runtime) ): ps_place += 1

				if ( compare_results(num_score, runtime, perfect_ps_score, perfect_ps_runtime) ):
					perfect_ps_runtime = runtime
					perfect_ps_score = num_score
					perfect_ps_succ_fail = succ_fail

		if options.debug:
			flog.write('{0} ps_tool={1} score={2} rt={3} place={4}\n\n'.format(filename, get_tool_name(ps_tool), ps_num_score, ps_runtime, ps_place))

		cat_tool_scores[(cat, MetaToolsType.tmax, ex)] += get_max_score(filename)
		ps_places_per_file[(cat, ps_place, ex)] += 1
		add_tool_result(MetaToolsType.perfect_ps, cat, perfect_ps_score, perfect_ps_runtime, perfect_ps_succ_fail)
		#echo cat=$cat cat_tool_runtimes_cat_ps=${cat_tool_runtimes[${cat}_ps_${ex}]}
	fprediction.close()

	flog.write('\nSumming up score for compound categories\n')
	for cat in compound_cats:
		flog.write('{0} subcats={1}\n'.format(cat, ', '.join(get_cat_name(c) for c in SubCat[cat])))
		for subcat in SubCat[cat]:
			add_subcat_result(cat, subcat)

		subcat_num=len(SubCat[cat])
		for tool in tools:
			#echo 'cat_tools_scores['${cat}'_'${tool}'_'${ex}']='${cat_tool_scores[${cat}_${tool}_${ex}]} 'file_num['${cat}']='${file_num[$cat]} subcat_num=$subcat_num
			cat_tool_scores[(cat, tool, ex)] = float(cat_tool_scores[(cat, tool, ex)]) * file_num[(cat,ex)] / subcat_num
			#echo 'cat_tools_scores['${cat}'_'${tool}'_'${ex}']='${cat_tool_scores[${cat}_${tool}_${ex}]}

def summarise_experiments():
	flog.write('\nSummarising the experiments: ex={0} exnum={1}\n'.format(ex, exnum))
	for cat in cats:
		file_num[(cat,EXSUM)] += file_num[(cat,ex)]
		for tool in tools:
			cat_tool_scores[(cat, tool, EXSUM)] += cat_tool_scores[(cat, tool, ex)]
			cat_tool_runtimes[(cat, tool, EXSUM)] += cat_tool_runtimes[(cat, tool, ex)]
			if ( tool != MetaToolsType.tmax ):
				for succ_fail in all_succ_fail:
					tool_succ_fail[(cat, tool, succ_fail, EXSUM)] += tool_succ_fail[(cat, tool, succ_fail, ex)]

			if ( tool in svcomp_tools ):
				choice[(cat, tool, EXSUM)] += choice[(cat, tool, ex)]
				cat_tool_nonparticip_chosen[(cat, tool, EXSUM)] += cat_tool_nonparticip_chosen[(cat, tool, ex)]

		choice[(cat, MetaToolsType.tools_none, EXSUM)] += choice[(cat, MetaToolsType.tools_none, ex)]
		for place in range(1, MetaToolsType.tools_none+1):
			ps_places_per_file[(cat, place, EXSUM)] += ps_places_per_file[(cat, place, ex)]

def normalise_experiments():
	num_of_ex=max_ex-min_ex+1;
	for cat in cats:
		file_num[(cat,EXSUM)] = float(file_num[(cat,EXSUM)])/num_of_ex
		for tool in tools:
			cat_tool_scores[(cat, tool, EXSUM)] = float(cat_tool_scores[(cat, tool, EXSUM)]) / num_of_ex
			cat_tool_runtimes[(cat, tool, EXSUM)] = float(cat_tool_runtimes[(cat, tool, EXSUM)]) / num_of_ex
			if ( tool != MetaToolsType.tmax ):
				for succ_fail in all_succ_fail:
					tool_succ_fail[(cat, tool, succ_fail, EXSUM)] = float(tool_succ_fail[(cat, tool, succ_fail, EXSUM)]) / num_of_ex

			if not ( is_meta_tool(tool) ):
				choice[(cat, tool, EXSUM)] = float(choice[(cat, tool, EXSUM)]) / num_of_ex
				cat_tool_nonparticip_chosen[(cat, tool, EXSUM)] = float(cat_tool_nonparticip_chosen[(cat, tool, EXSUM)]) / num_of_ex
		choice[(cat, MetaToolsType.tools_none, EXSUM)] = float(choice[(cat, MetaToolsType.tools_none, EXSUM)]) / num_of_ex

		for place in range(1, MetaToolsType.tools_none+1):
			ps_places_per_file[(cat, place, EXSUM)] = float(ps_places_per_file[(cat, place, EXSUM)]) / num_of_ex

def compare_place(x, y):
	if (x == y): res=0
	elif (cat_tool_scores[x] > cat_tool_scores[y] or
				(cat_tool_scores[x] == cat_tool_scores[y] and cat_tool_runtimes[x] < cat_tool_runtimes[y])):
					res=-1
	else: res=1

	return res

def compare_medals(x, y):
	tool1=x[0]; ex1=x[1]
	tool2=y[0]; ex2=y[1]

	for place in range(1, len(svcomp_tools)+1+1):
		m1=tool_medals[(tool1, place, ex1)]
		m2=tool_medals[(tool2, place, ex1)]
		if (m1 > m2):
			return -1
		elif (m1 < m2):
			return 1
	return 0
	

def sort_by_svcomp_place(tools, cat, ex):
	return sorted(tools, cmp=lambda t1, t2 : compare_place((cat, t1, ex), (cat, t2, ex)))

def sort_by_medals(tools, ex):
	return sorted(tools, cmp=lambda t1, t2: compare_medals((t1, ex), (t2, ex)))

def create_arr(f):
	arr=[]
	for ex in range(min_ex, max_ex+1):
		arr.append(f(ex))
#	print(arr)
	return arr

def get_stat(f, prec):
	p=str(prec)
	p1=str(prec+1)
	arr=create_arr(f)
	s='std={0:.'+p1+'f} md={1:.'+p+'f} me={2:.'+p+'f} '+\
			'[{3:.'+p+'f}, {4:.'+p+'f}]'
#	print(s+'\n')
	return s.format(statistics.pstdev(arr),
													statistics.median(arr),
													statistics.mean(arr),
													min(arr),max(arr))

def get_place_str(cat, tool, ex, place):
	str='{0:d}\t{1:s}\t{2:.0f}'.format(place, get_tool_name(tool),
										cat_tool_scores[(cat, tool, ex)])
	if (ex == EXSUM and tool in svcomp_tools+[MetaToolsType.ps, MetaToolsType.tmax]):
		str = str + ' ({0})'.format(get_stat(lambda i: cat_tool_scores[(cat,tool,i)], 0))

	str = str + '\t{0:.1f}'.format(cat_tool_runtimes[(cat, tool, ex)])

	if (ex == EXSUM and tool in svcomp_tools+[MetaToolsType.ps]):
		str = str + ' ({0})'.format(get_stat(lambda i: cat_tool_runtimes[(cat,tool,i)],1))

	return str+'\n'

def print_cat_tool_score_runtime():
	#`echo $categories ControlFlow | tr ' ' '\n' | sort | tr '\n' ' '`
	reported_tools=[];
	for tool in svcomp_tools:
		if not ( is_excluded_tool(tool) ): reported_tools.append(tool)

	for cat in cats:
		tool_places=sort_by_svcomp_place(reported_tools + [MetaToolsType.ps], cat, ex)
		#print('tool_places: {0}'.format(tool_places))
		tool_places_wo_ps=sort_by_svcomp_place(reported_tools, cat, ex)

		flog.write('\n{0}\n'.format(get_cat_name(cat)))

		flog.write(get_place_str(cat, MetaToolsType.tmax, ex, 0))
		for x in enumerate(tool_places):
			flog.write('{0}'.format(get_place_str(cat, x[1], ex, x[0]+1)))

		if ( ex == EXSUM ):
			ftable_tool_places.write(get_cat_name(cat))

		for tool in svcomp_tools + [MetaToolsType.ps]:
			if not ( is_excluded_tool(tool) ):

				cat_tool_places[(cat, tool)] = tool_places.index(tool)+1
				if (tool != MetaToolsType.ps): cat_tool_places_wo_ps[(cat, tool)] = tool_places_wo_ps.index(tool)+1

				if ( ex == EXSUM ):
					ftable_tool_places.write("\t{0} {1:.0f} {2:.0f}".format(cat_tool_places[(cat, tool)],
																				cat_tool_scores[(cat, tool, ex)],
																				cat_tool_runtimes[(cat, tool, ex)]))

				if ( not cat in SubCat[CatsType.ControlFlow] ):
					place = cat_tool_places[(cat, tool)]
					tool_medals[(tool, place, ex)] += 1

		if ( ex == EXSUM ):
			for tool in meta_tools:
				if ( tool != MetaToolsType.ps and tool != MetaToolsType.tmax ):
					ftable_tool_places.write("\t0 {0:.0f} {1:.0f}".format(cat_tool_scores[(cat, tool, ex)],
																			cat_tool_runtimes[(cat, tool, ex)]))
			ftable_tool_places.write('\n')

def print_medals():
	flog.write('\nMedal counts:\n')
	if ( ex == EXSUM ):
		ftable_tool_places.write("Medals")

		for tool in svcomp_tools + [MetaToolsType.ps]:
			if not (is_excluded_tool(tool)):
				s="/".join(str(tool_medals[(tool, place, ex)]) for place in range(1,3+1))
				ftable_tool_places.write('\t{0}'.format(s))

		ftable_tool_places.write('\n')

	for tool in sort_by_medals(svcomp_tools + [MetaToolsType.ps], ex):
		flog.write('{0}:'.format(get_tool_name(tool)))
		for place in range(1, MetaToolsType.tools_none+1):
			flog.write(' {0}: {1}'.format(place, tool_medals[(tool, place, ex)]))
			if ex == EXSUM:
				flog.write(' ({0})\n'.format(get_stat(lambda i: tool_medals[(tool,place,i)],0)))
		flog.write('\n')

def print_places_of_chosen_tools():
	flog.write('\nPlace distribution per file:\n')
	for cat in cats:
		flog.write('{0}:'.format(get_cat_name(cat)))
		for place in range(1, MetaToolsType.tools_none+1):
			perc = compute_perc(ps_places_per_file[(cat, place, ex)], file_num[(cat,ex)])
			flog.write('{0:d}: {1:.0f}% '.format(place, perc))
		flog.write('\n')

def print_tool_succ_fail():
	flog.write('\nTool success/failure distribution per file:\n')
	for cat in cats:
		flog.write('{0} ({1} files):\n'.format(get_cat_name(cat), file_num[(cat,ex)]))

		if ( ex == EXSUM ):
			ftable_used_tools.write(get_cat_name(cat))
			ftable_succ_fail.write(get_cat_name(cat))

		for tool in tools + [MetaToolsType.tools_none]:
			if not ( tool == MetaToolsType.tmax or tool == MetaToolsType.tools_none or is_excluded_tool(tool) ):
				succ_fail_str=""
				succ_fail_sum=0
				flog.write('{0} '.format(get_tool_name(tool)))
				for succ_fail in all_succ_fail:
					perc = round(compute_perc(tool_succ_fail[(cat, tool, succ_fail, ex)], file_num[(cat,ex)]))
					flog.write("{0}: {1:.0f} ({2:.0f}%) ".format(succ_fail_to_str(succ_fail),
																	tool_succ_fail[(cat, tool, succ_fail, ex)],
																	perc))
					if (ex == EXSUM):
						flog.write('{0} '.format(get_stat(lambda i: round(compute_perc(tool_succ_fail[(cat,tool,succ_fail,i)],
																						file_num[(cat,i)])),0)))
						if (succ_fail != SuccFailType.unknown):
							succ_fail_sum += perc
						else:
							perc = 100 - succ_fail_sum

						succ_fail_str += ' {0:.0f}'.format(perc)

				if (ex == EXSUM):
					ftable_succ_fail.write("\t{0}".format(succ_fail_str))


				flog.write('\n')

		#with open(tmp, 'w') as ftmp:

			if (tool==MetaToolsType.tools_none): flog.write('none ')
			if ( tool == MetaToolsType.tools_none or (not is_meta_tool(tool)) ):
				perc_cat = compute_perc(choice[(cat, tool, ex)], file_num[(cat,ex)])
				#if ( choice[(cat, tool, ex)] > 0 ):
				#	s='{0} ({1}.place): {2} ({3}%)\n'.format(get_tool_name(tool), cat_tool_places_wo_ps[(cat, tool)],
				#												choice[(cat, tool, ex)], perc_cat)
				#	ftmp.write(s)

				flog.write('\t\tused {0:.2f}\%'.format(perc_cat))
				if ( ex == EXSUM ):
					ftable_used_tools.write("\t{0:.2f}".format(perc_cat))
					flog.write(' ({0})'.format(get_stat(lambda i:compute_perc(choice[(cat,tool,i)],file_num[(cat,i)]), 2)))
				flog.write('\n')

		flog.write('\n')

		if ( ex == EXSUM ):
			ftable_succ_fail.write('\n')
			ftable_used_tools.write('\n')

		#os.system('sort -k3,3n {0} > {0}1 && mv {0}1 {0}'.format(tmp))
		#print_file(tmp)

def print_nonparticip_chosen():
	flog.write('\nNon-participating tools chosen:\n')
	for cat in cats:
		flog.write('{0}:'.format(get_cat_name(cat)))
		s=0
		for tool in svcomp_tools:
			flog.write(' {0}: {1}'.format(get_tool_name(tool), cat_tool_nonparticip_chosen[(cat, tool, ex)]))
			s += cat_tool_nonparticip_chosen[(cat, tool, ex)]
		flog.write(" total: {0} ({1}%)".format(s, compute_perc(s, file_num[(cat,ex)])))

def print_results():
	print_cat_tool_score_runtime()
	print_medals()
	print_places_of_chosen_tools()
	print_tool_succ_fail()
#	print_nonparticip_chosen()

EXSUM = 0
cur_ex = -1

min_ex = int(options.min_ex)
max_ex = int(options.max_ex)

exnum=min_ex
#ex=cur_ex

def print_time():
	t=strftime("%a, %d %b %Y %H:%M:%S +0000", gmtime())
	print('{0}\n'.format(t))

for i in range(min_ex, max_ex+1):
	print('running experiment {0}\n'.format(exnum))
	print_time()
	exnum = i
	ex=i
	init()
	calculate_scores_runtimes()
	summarise_experiments()
	flog.write('\nresults of experiment {0:d}:'.format(exnum))
	print_results()
	print_time()

normalise_experiments()

ex = EXSUM
flog.write('\nsummary results:\n')
print_results()

#rm -f ${tmp}*
flog.write('{0:s}\n'.format(subprocess.check_output("date +'%D %X'", shell=True)))
flog.write('tmp = {0}\n'.format(tmp))

